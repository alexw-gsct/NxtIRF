#' @export
FindSamples <- function(sample_path, suffix = ".txt.gz", use_subdir = FALSE) {
    assertthat::assert_that(dir.exists(sample_path),
        msg = "Given path does not exist")
    
    files_found = list.files(pattern = paste0("\\", suffix, "$"),
        path = normalizePath(sample_path), full.names = TRUE, recursive = TRUE)
    if(length(files_found) > 0) {
      df = data.frame(sample = "", path = files_found)
      if(use_subdir) {
          df$sample = basename(dirname(df$path))
      } else {
          df$sample = sub(suffix,"",basename(df$path))
      }
      return(df)
    } else {
      return(NULL)
    }
}

#' Processes data from IRFinder output
#'
#' @param Experiment: A data frame containing the necessary information. The first column is the base name of the sample files. The second column is the sample name. All subsequent columns are assumed to be experimental conditions / annotation data (e.g. gender, age, treatment response, etc)
#' @param reference_path: THe path to the reference generated by BuildReference()
#' @param output_path: The path to the output generated by data collation.
#' @export
CollateData <- function(Experiment, reference_path, output_path, localHub = FALSE) {
    assertthat::assert_that("data.frame" %in% class(Experiment),
        msg = "Experiment object needs to be a data frame")
    assertthat::assert_that(ncol(Experiment) >= 2,
        msg = "Experiment needs to contain two columns containing (1) sample name and (2) IRFinder output")

    assertthat::assert_that(file.exists(file.path(reference_path, "settings.Rds")),
        msg = paste(file.path(reference_path, "settings.Rds"), "does not exist"))


		settings = readRDS(file.path(reference_path, "settings.Rds"))
		if(settings$ah_genome != "") {
			genome = FetchAH(ah_genome, localHub = localHub)
		} else {
			genome = Biostrings::readDNAStringSet(
				normalizePath(file.path(reference_path, basename(settings$fasta_file)))
			)
		}
    
    colnames(Experiment)[1:2] = c("sample", "path")
    # TODO: check each file within Experiment$path is valid
    
    # Create a subdirectory for each sample within output_path
    base_output_path = normalizePath(dirname(output_path))      # TODO check if this fails
    norm_output_path = file.path(base_output_path, basename(output_path))
    if(!dir.exists(norm_output_path)) {
        dir.create(norm_output_path)
    }
    
    df.internal = Experiment[,1:2]
    df.internal$paired = FALSE
    df.internal$strand = 0
    df.internal$depth = 0

    for(i in 1:nrow(df.internal)) {
        message(paste("Processing stats of file ", i))
        stats = suppressWarnings(fread(df.internal$path[i], skip = "BAM"))
        stats$Value = as.numeric(stats$Value)
        if(stats$Value[3] == 0 & stats$Value[4] > 0) {
            df.internal$paired[i] = TRUE
            df.internal$depth[i] = stats$Value[4]
        } else if(stats$Value[3] > 0 && stats$Value[4] / stats$Value[3] / 1000) {
            df.internal$paired[i] = TRUE
            df.internal$depth[i] = stats$Value[4]
        } else {
            df.internal$paired[i] = FALSE
            df.internal$depth[i] = stats$Value[3]
        }
        direct = suppressWarnings(fread(df.internal$path[i], skip = "Directionality"))
        direct$Value = as.numeric(direct$Value)
        df.internal$strand[i] = direct$Value[9]
    }
    gc()
    
    if(any(df.internal$strand == 0)) {
        runStranded = FALSE
    } else {
        runStranded = TRUE
    }
    
    # Compile junctions and IR lists first, save to temp files
    for(i in 1:nrow(df.internal)) {
        message(paste("Compiling junction and IR lists from sample: ", i))
        junc = suppressWarnings(as.data.table(fread(df.internal$path[i], skip = "JC_seqname")))
        setnames(junc, "JC_seqname", "seqnames")
        if(!exists("junc.common")) {
            junc.common = junc[,1:4]
        } else {
            junc.common = merge(junc.common, junc[,1:4], all = T)
        }
		# Write temp file
        fst::write.fst(as.data.frame(junc), 
            file.path(norm_output_path, paste(Experiment$sample[i], "junc.fst.tmp", sep=".")))

        
		# Compile IRFinder based on strand
		if(!runStranded) {
            irf = suppressWarnings(as.data.table(fread(Experiment$path[i], skip = "Nondir_")))
            setnames(irf, c("Nondir_Chr", "Start", "End", "Strand"), c("seqnames","start","end", "strand"))
            if(!exists("irf.common")) {
                irf.common = irf[,1:6]
            } else {
                irf.common = semi_join.DT(irf.common, irf[,1:6], by = colnames(irf.common))
            }
		} else {
            irf = suppressWarnings(as.data.table(fread(Experiment$path[i], skip = "Dir_Chr")))
            setnames(irf, c("Dir_Chr", "Start", "End", "Strand"), c("seqnames","start","end", "strand"))
            if(!exists("irf.common")) {
                irf.common = irf[,1:6]
            } else {
                irf.common = semi_join.DT(irf.common, irf[,1:6], by = colnames(irf.common))
            }
		}
        fst::write.fst(as.data.frame(irf), 
            file.path(norm_output_path, paste(Experiment$sample[i], "irf.fst.tmp", sep=".")))
    }

    irf.common[, start := start + 1]
    junc.common[, start := start + 1]

# Reassign +/- based on junctions.fst annotation
    # Annotate junctions
    candidate.introns = as.data.table(fst::read.fst(file.path(reference_path, "fst", "junctions.fst")))

    junc.strand = unique(candidate.introns[, c("seqnames", "start", "end", "strand")])

    junc.common[, strand := NULL]
    junc.common = unique(junc.common)
    junc.common = merge(junc.common, junc.strand, all = TRUE, by = c("seqnames", "start", "end"))
    junc.common[is.na(strand), strand := "*"]

    left.gr = GRanges(seqnames = junc.common$seqnames, 
        ranges = IRanges(start = junc.common$start, end = junc.common$start + 1), strand = "+")
    right.gr = GRanges(seqnames = junc.common$seqnames, 
        ranges = IRanges(start = junc.common$end - 1, end = junc.common$end), strand = "+")
        
    left.seq = BSgenome::getSeq(genome, left.gr)
    right.seq = BSgenome::getSeq(genome, right.gr)

    junc.common$motif_pos = paste0(as.character(left.seq), as.character(right.seq))
    junc.common$motif_infer_strand = "n"
    junc.common[ motif_pos %in% c("GTAG", "GCAG", "ATAC", "ATAG"), motif_infer_strand := "+"]
    junc.common[ motif_pos %in% c("CTAC", "CTGC", "GTAT", "CTAT"), motif_infer_strand := "-"]
    junc.common[ motif_pos %in% c("GTAC"), motif_infer_strand := "n"]       # Do not accept un-annotated GTACs - too confusing
    # Exclude non-splice motifs (that are also not annotated - i.e. strand == "*")
    junc.common = junc.common[motif_infer_strand != "n" | strand != "*"]

    # Use motif_infer_strand (only for *)
    # junc.common = junc.common[motif_infer_strand == "n", motif_infer_strand := strand]
    # junc.common$strand = NULL
    # setnames(junc.common, "motif_infer_strand", "strand")
    junc.common[strand == "*", strand := motif_infer_strand]
    junc.common$motif_infer_strand = NULL
    
    # Should splicing across gene groups be allowed? Exclude
    Genes = GenomicRanges::makeGRangesFromDataFrame(
        fst::read.fst(file.path(reference_path, "fst", "Genes.fst"))
    )

    # Exclude distant splice events:

    # Genes.Group.stranded = as.data.table(
        # GenomicRanges::reduce(c(Genes, GenomicRanges::flank(Genes, 5000),
        # GenomicRanges::flank(Genes, 5000, start = FALSE))
    # ))
    # setorder(Genes.Group.stranded, seqnames, start, strand)
    # Genes.Group.stranded[, gene_group_stranded := .I]
    
    # junc.common.left = copy(junc.common)
    # junc.common.left[, start := start - 1]
    # junc.common.left[, end := start + 1]
    # OL = suppressWarnings(
        # GenomicRanges::findOverlaps(
            # GenomicRanges::makeGRangesFromDataFrame(as.data.frame(junc.common.left)), 
            # GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Genes.Group.stranded))
        # )
    # )
    # junc.common$gene_group_left[OL@from] = Genes.Group.stranded$gene_group_stranded[OL@to]

    # junc.common.right = copy(junc.common)
    # junc.common.right[, end := end + 1]
    # junc.common.right[, start := end - 1]
    # OL = suppressWarnings(
        # GenomicRanges::findOverlaps(
            # GenomicRanges::makeGRangesFromDataFrame(as.data.frame(junc.common.right)), 
            # GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Genes.Group.stranded))
        # )
    # )
    # junc.common$gene_group_right[OL@from] = Genes.Group.stranded$gene_group_stranded[OL@to]
        

    # junc.common = junc.common[gene_group_left == gene_group_right & !is.na(gene_group_left)]
    # junc.common$gene_group_left = NULL
    # junc.common$gene_group_right = NULL
    
    # Assign region names to junctions:
    junc.common[, Event := paste0(seqnames, ":", start, "-", end, "/", strand)]
    
    candidate.introns[, transcript_biotype_2 := transcript_biotype]
    candidate.introns[!(transcript_biotype %in% c("protein_coding", "processed_transcript",
        "lincRNA", "antisense", "nonsense_mediated_decay")), transcript_biotype_2 := "other"]

    candidate.introns[, transcript_biotype_2 := factor(transcript_biotype_2, c("protein_coding", "processed_transcript",
        "lincRNA", "antisense", "other", "nonsense_mediated_decay"), ordered = TRUE)]
        
    if("transcript_support_level" %in% colnames(candidate.introns)) {
        setorder(candidate.introns, transcript_biotype_2, transcript_support_level)
    } else {
        setorder(candidate.introns, transcript_biotype_2)    
    }
    introns.unique = unique(candidate.introns, by = c("seqnames", "start", "end", "width", "strand"))
    setorder(introns.unique, seqnames, start, end, strand)

    junc.annotation = introns.unique[junc.common, 
        c("seqnames", "start", "end", "strand", "transcript_id", "intron_number", "gene_name", "gene_id", "transcript_biotype"),
        on = c("seqnames", "start", "end", "strand")]
    
    # Use Exon Groups file to designate exon groups to all junctions
    Exon.Groups = GenomicRanges::makeGRangesFromDataFrame(
        fst::read.fst(file.path(reference_path, "fst", "Exons.groups.fst")),
        keep.extra.columns = TRUE)
    
    # Always calculate stranded for junctions
    # if(!runStranded) {
        # Exon.Groups = Exon.Groups[strand(Exon.Groups) == "*"]
    # } else {
        # Exon.Groups = Exon.Groups[strand(Exon.Groups) != "*"]    
    # }
    Exon.Groups.S = Exon.Groups[strand(Exon.Groups) != "*"]    
    
    junc.common.left = copy(junc.common)
    junc.common.left[, start := start - 1]
    junc.common.left[, end := start + 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(junc.common.left)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    junc.common$gene_group_left[OL@from] = Exon.Groups.S$gene_group[OL@to]
    junc.common$exon_group_left[OL@from] = Exon.Groups.S$exon_group[OL@to]

    junc.common.right = copy(junc.common)
    junc.common.right[, end := end + 1]
    junc.common.right[, start := end - 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(junc.common.right)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    junc.common$gene_group_right[OL@from] = Exon.Groups.S$gene_group[OL@to]
    junc.common$exon_group_right[OL@from] = Exon.Groups.S$exon_group[OL@to]
    
    junc.common[, JG_up := ""]
    junc.common[, JG_down := ""]
    junc.common[strand == "+" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        JG_up := paste(gene_group_left, exon_group_left, sep="_")]
    junc.common[strand == "-" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        JG_up := paste(gene_group_right, exon_group_right, sep="_")]
    junc.common[strand == "+" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        JG_down := paste(gene_group_right, exon_group_right, sep="_")]
    junc.common[strand == "-" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        JG_down := paste(gene_group_left, exon_group_left, sep="_")]

    junc.common$gene_group_left = NULL
    junc.common$gene_group_right = NULL
    junc.common$exon_group_left = NULL
    junc.common$exon_group_right = NULL
    
    irf.common.left = copy(irf.common)
    irf.common.left[, start := start - 1]
    irf.common.left[, end := start + 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(irf.common.left)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    irf.common$gene_group_left[OL@from] = Exon.Groups.S$gene_group[OL@to]
    irf.common$exon_group_left[OL@from] = Exon.Groups.S$exon_group[OL@to]

    irf.common.right = copy(irf.common)
    irf.common.right[, end := end + 1]
    irf.common.right[, start := end - 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(irf.common.right)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    irf.common$gene_group_right[OL@from] = Exon.Groups.S$gene_group[OL@to]
    irf.common$exon_group_right[OL@from] = Exon.Groups.S$exon_group[OL@to]
    
    irf.common[, JG_up := ""]
    irf.common[, JG_down := ""]
    irf.common[strand == "+" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        JG_up := paste(gene_group_left, exon_group_left, sep="_")]
    irf.common[strand == "-" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        JG_up := paste(gene_group_right, exon_group_right, sep="_")]
    irf.common[strand == "+" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        JG_down := paste(gene_group_right, exon_group_right, sep="_")]
    irf.common[strand == "-" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        JG_down := paste(gene_group_left, exon_group_left, sep="_")]

    irf.common$gene_group_left = NULL
    irf.common$gene_group_right = NULL
    irf.common$exon_group_left = NULL
    irf.common$exon_group_right = NULL
    
    if(!runStranded) {
        Exon.Groups = Exon.Groups[strand(Exon.Groups) == "*"]
    } else {
        Exon.Groups = Exon.Groups[strand(Exon.Groups) != "*"]    
    }
    irf.common.left = copy(irf.common)
    irf.common.left[, start := start - 1]
    irf.common.left[, end := start + 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(irf.common.left)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    irf.common$gene_group_left[OL@from] = Exon.Groups.S$gene_group[OL@to]
    irf.common$exon_group_left[OL@from] = Exon.Groups.S$exon_group[OL@to]

    irf.common.right = copy(irf.common)
    irf.common.right[, end := end + 1]
    irf.common.right[, start := end - 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(irf.common.right)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    irf.common$gene_group_right[OL@from] = Exon.Groups.S$gene_group[OL@to]
    irf.common$exon_group_right[OL@from] = Exon.Groups.S$exon_group[OL@to]
    
    irf.common[, IRG_up := ""]
    irf.common[, IRG_down := ""]
    irf.common[strand == "+" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        IRG_up := paste(gene_group_left, exon_group_left, sep="_")]
    irf.common[strand == "-" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        IRG_up := paste(gene_group_right, exon_group_right, sep="_")]
    irf.common[strand == "+" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        IRG_down := paste(gene_group_right, exon_group_right, sep="_")]
    irf.common[strand == "-" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        IRG_down := paste(gene_group_left, exon_group_left, sep="_")]
    irf.common$gene_group_left = NULL
    irf.common$gene_group_right = NULL
    irf.common$exon_group_left = NULL
    irf.common$exon_group_right = NULL

    irf.common[, EventRegion := paste0(seqnames, ":", start, "-", end, "/", strand)]

    Splice.Anno = as.data.table(fst::read.fst(file.path(reference_path, "fst", "Splice.fst")))
    candidate.introns[, Event1a := Event]
    candidate.introns[, Event2a := Event]
    Splice.Anno[candidate.introns, on = "Event1a", up_1a := paste(i.gene_group_stranded, 
        i.exon_group_stranded_upstream, sep="_")]
    Splice.Anno[candidate.introns, on = "Event1a", down_1a := paste(i.gene_group_stranded, 
        i.exon_group_stranded_downstream, sep="_")]
    Splice.Anno[candidate.introns, on = "Event2a", down_2a := paste(i.gene_group_stranded, 
        i.exon_group_stranded_downstream, sep="_")]
    
    Splice.Anno[EventType %in% c("MXE", "SE", "ALE", "A3SS"),
        JG_up := up_1a]
    Splice.Anno[EventType %in% c("SE", "AFE", "A5SS"),
        JG_down := down_1a]
    Splice.Anno[EventType %in% c("MXE"),
        JG_down := down_2a]
    
    Splice.Anno$up_1a = NULL
    Splice.Anno$down_1a = NULL
    Splice.Anno$down_2a = NULL
    Splice.Anno[, strand := tstrsplit(Event1a, split="/")[[2]]]
    
    rm(candidate.introns, introns.unique)
    gc()

    for(i in seq_len(nrow(df.internal))) {
        message(paste("Processing data for sample: ", i))
        junc = as.data.table(
            fst::read.fst(file.path(norm_output_path, paste(Experiment$sample[i], "junc.fst.tmp", sep=".")))
        )
        # setnames(junc, "JC_seqname", "seqnames")
        junc[, start := start + 1]
        junc$strand = NULL

        junc = junc[junc.common, on = colnames(junc.common)[1:3]]
        
        if(df.internal$strand[i] == 0) {
            junc$count = junc$total    
        } else if(df.internal$strand[i] == -1) {
            junc$count = 0
            junc[strand == "+", count := neg]
            junc[strand == "-", count := pos]
            junc[strand == "*", count := total]
        } else {
            junc$count = 0
            junc[strand == "+", count := pos]
            junc[strand == "-", count := neg]
            junc[strand == "*", count := total]    
        }
        junc[is.na(count), count := 0]
        junc = junc[,c("seqnames", "start", "end", "strand", "Event", "count")]
        junc = cbind(junc, junc.common[, c("JG_up", "JG_down")])
        junc[, SO_L := 0]
        junc[, SO_R := 0]
        junc[JG_up != "" & strand == "+", SO_L := sum(count), by = "JG_up"]
        junc[JG_down != "" & strand == "+", SO_R := sum(count), by = "JG_down"]
        junc[JG_up != "" & strand == "-", SO_R := sum(count), by = "JG_up"]
        junc[JG_down != "" & strand == "-", SO_L := sum(count), by = "JG_down"]
        
        fst::write.fst(as.data.frame(junc), 
            file.path(norm_output_path, paste(Experiment$sample[i], "junc.fst", sep=".")))
        
        splice = copy(Splice.Anno)
        
        splice[, count_Event1a := 0]
        splice[!is.na(Event1a), count_Event1a := junc$count[match(Event1a, junc$Event)]]
        splice[is.na(count_Event1a), count_Event1a := 0]
        splice[, count_Event2a := 0]
        splice[!is.na(Event2a), count_Event2a := junc$count[match(Event2a, junc$Event)]]
        splice[is.na(count_Event2a), count_Event2a := 0]
        splice[, count_Event1b := 0]
        splice[!is.na(Event1b), count_Event1b := junc$count[match(Event1b, junc$Event)]]
        splice[is.na(count_Event1b), count_Event1b := 0]
        splice[, count_Event2b := 0]
        splice[!is.na(Event2b), count_Event2b := junc$count[match(Event2b, junc$Event)]]
        splice[is.na(count_Event2b), count_Event2b := 0]

        splice[, count_JG_up := 0]
        splice[!is.na(JG_up) & strand == "+", count_JG_up := junc$SO_L[match(JG_up, junc$JG_up)]]
        splice[!is.na(JG_up) & strand == "-", count_JG_up := junc$SO_R[match(JG_up, junc$JG_up)]]
        splice[is.na(count_JG_up), count_JG_up := 0]
        splice[, count_JG_down := 0]
        splice[!is.na(JG_down) & strand == "-", count_JG_down := junc$SO_L[match(JG_down, junc$JG_down)]]
        splice[!is.na(JG_down) & strand == "+", count_JG_down := junc$SO_R[match(JG_down, junc$JG_down)]]
        splice[is.na(count_JG_down), count_JG_down := 0]

        # Splice participation: sum of two events compared to JG_up / JG_down
        splice[, partic_up := 0]
        splice[, partic_down := 0]

        splice[EventType %in% c("MXE", "SE", "ALE", "A3SS"), partic_up := count_Event1a + count_Event1b]
        splice[EventType %in% c("MXE"), partic_down := count_Event2a + count_Event2b]
        splice[EventType %in% c("SE"), partic_down := count_Event2a + count_Event1b]
        splice[EventType %in% c("AFE", "A5SS"), partic_down := count_Event1a + count_Event1b]

        # Splice coverage = participation / max_JG
        
        splice[, cov_up := 0]
        splice[count_JG_up > 0, cov_up := partic_up / count_JG_up]
        splice[, cov_down := 0]
        splice[count_JG_down > 0, cov_down := partic_down / count_JG_down]
        splice[EventType %in% c("MXE", "SE") & cov_up < cov_down, coverage := cov_up]
        splice[EventType %in% c("MXE", "SE") & cov_up >= cov_down, coverage := cov_down]
        splice[EventType %in% c("ALE", "A3SS"), coverage := cov_up]
        splice[EventType %in% c("AFE", "A5SS"), coverage := cov_down]
        
        irf = as.data.table(
            fst::read.fst(file.path(norm_output_path, paste(Experiment$sample[i], "irf.fst.tmp", sep=".")))
        )
        irf[, start := start + 1]
        irf = irf[irf.common, on = colnames(irf.common)[1:6], EventRegion := i.EventRegion]
        
        # Extra statistics:
        irf[, SpliceMax := 0]
        irf[SpliceLeft >= SpliceRight, SpliceMax := SpliceLeft]
        irf[SpliceLeft < SpliceRight, SpliceMax := SpliceRight]

        irf[junc, on = c("seqnames", "start", "end", "strand"), SpliceOverLeft := SO_L]
        irf[junc, on = c("seqnames", "start", "end", "strand"), SpliceOverRight := SO_R]
        irf[SpliceOverLeft >= SpliceOverRight, SpliceOverMax := SpliceOverLeft]
        irf[SpliceOverLeft < SpliceOverRight, SpliceOverMax := SpliceOverRight]
        
        irf[, IROratio := 0]
        irf[IntronDepth < 1 & IntronDepth > 0 & (Coverage + SpliceOverMax) > 0, IROratio := Coverage / (Coverage + SpliceOverMax)]
        irf[IntronDepth >= 1, IROratio := IntronDepth / (IntronDepth + SpliceOverMax)]

        irf[, TotalDepth := IntronDepth + SpliceOverMax]

        splice.no_region = splice[!(EventRegion %in% irf$EventRegion)]
        splice.no_region[, Depth1a := irf$TotalDepth[match(Event1a, irf$EventRegion)]]
        splice.no_region[, Depth2a := irf$TotalDepth[match(Event2a, irf$EventRegion)]]
        splice.no_region[, Depth1b := irf$TotalDepth[match(Event1b, irf$EventRegion)]]
        splice.no_region[, Depth2b := irf$TotalDepth[match(Event2b, irf$EventRegion)]]
        splice.no_region[, Depth := 0]
        splice.no_region[count_JG_up > count_JG_down, Depth := count_JG_up]
        splice.no_region[count_JG_up <= count_JG_down, Depth := count_JG_down]
        splice.no_region[is.na(Depth1a), Depth1a := 0]
        splice.no_region[is.na(Depth1b), Depth1b := 0]
        splice.no_region[is.na(Depth2a), Depth2a := 0]
        splice.no_region[is.na(Depth2b), Depth2b := 0]
        splice.no_region[Depth1a > Depth2a, DepthA := Depth1a]
        splice.no_region[Depth1b > Depth2b, DepthB := Depth1b]
        splice.no_region[Depth1a <= Depth2a, DepthA := Depth2a]
        splice.no_region[Depth1b <= Depth2b, DepthB := Depth2b]
        splice.no_region[DepthA > DepthB, Depth := DepthA]
        splice.no_region[DepthA <= DepthB, Depth := DepthB]

        splice[, TotalDepth := 0]
        splice[irf, on = "EventRegion", TotalDepth := i.TotalDepth]
        splice[splice.no_region, on = "EventName", TotalDepth := i.Depth]

        fst::write.fst(as.data.frame(splice), 
            file.path(norm_output_path, paste(Experiment$sample[i], "splice.fst", sep=".")))
        
        fst::write.fst(as.data.frame(irf),
            file.path(norm_output_path, paste(Experiment$sample[i], "irf.fst", sep=".")))
            
        file.remove(file.path(norm_output_path, paste(Experiment$sample[i], "junc.fst.tmp", sep=".")))
        file.remove(file.path(norm_output_path, paste(Experiment$sample[i], "irf.fst.tmp", sep=".")))
    }
    message("NxtIRF FST files generated")
}

#' @export
BuildFilterData = function(irf_fst_files, colData) {
	# Builds all necessary data from fst files in order to decide which events will be filtered by data filters
		
	assertthat::assert_that(all(grepl("\\.irf.fst$", irf_fst_files)),
		msg = "irf_fst_files must end in '.irf.fst'")
	assertthat::assert_that(all(file.exists(irf_fst_files)),
		msg = "Some IRFinder fst files do not exist")
	
  df = data.frame(sample = colData[,1], base_name = gsub("\\.irf.fst$", "", irf_fst_files),
    irf_file = irf_fst_files, stringsAsFactors = FALSE)
		
  df$splice_file = paste0(df$base_name, ".splice.fst")
	
	# skinny annotation
	irf.anno.brief = as.data.table(fst::read.fst(df$irf_file[1]))
	setnames(irf.anno.brief, "Name", "EventName")
	irf.anno.brief[, EventType := "IR"]
	irf.anno.brief[, EventRegion := paste0(seqnames, ":", start, "-", end, "/", strand)]
	irf.anno.brief = irf.anno.brief[, c("EventName", "EventType", "EventRegion")]
  splice.anno.brief = as.data.table(fst::read.fst(df$splice_file[1], c("EventName", "EventType", "EventRegion")))
	
	rowEvent = rbind(irf.anno.brief, splice.anno.brief)
			
	rowEvent.Depth = copy(rowEvent)
	rowEvent.Coverage = copy(rowEvent)
	rowEvent.minDepth = copy(rowEvent)
	
	# for minCov, Coverage uses IntronDepth for IR.
		# for splicing, we test whether the sum of both EventA+EventB is dominant (e.g. over 60%)
		#		if the sum of all transcripts mapped i.e. count_JG_(up/down) is low, then coverage is likely 
		# 	particulate (i.e. unreliable). Hence, use count_JG_(up/down) as minDepth 
        # splice[EventType %in% c("MXE", "SE") & cov_up < cov_down, coverage := cov_up]
        # splice[EventType %in% c("MXE", "SE") & cov_up >= cov_down, coverage := cov_down]
        # splice[EventType %in% c("ALE", "A3SS"), coverage := cov_up]
        # splice[EventType %in% c("AFE", "A5SS"), coverage := cov_down]		
				
	for(i in seq_len(nrow(df))) {
    message(paste("Processing sample", i))
    irf = as.data.table(fst::read.fst(df$irf_file[i]))
    setnames(irf, "Name", "EventName")
    splice = as.data.table(fst::read.fst(df$splice_file[i]))
    
    rowEvent.Depth[, c(df$sample[i]) := 0]
    rowEvent.Depth[irf, on = "EventName", c(df$sample[i]) := TotalDepth]
    rowEvent.Depth[splice, on = "EventName", c(df$sample[i]) := TotalDepth]
    
    rowEvent.Coverage[, c(df$sample[i]) := 0]
    rowEvent.Coverage[irf, on = "EventName", c(df$sample[i]) := Coverage]
    rowEvent.Coverage[splice, on = "EventName", c(df$sample[i]) := coverage]

    rowEvent.minDepth[, c(df$sample[i]) := 0]
    rowEvent.minDepth[irf, on = "EventName", c(df$sample[i]) := IntronDepth]
    rowEvent.minDepth[splice[
				EventType %in% c("MXE", "SE") & cov_up < cov_down
			], on = "EventName", c(df$sample[i]) := count_JG_up]
    rowEvent.minDepth[splice[
				EventType %in% c("MXE", "SE") & cov_up >= cov_down
			], on = "EventName", c(df$sample[i]) := count_JG_down]			
    rowEvent.minDepth[splice[
				EventType %in% c("ALE", "A3SS")
			], on = "EventName", c(df$sample[i]) := count_JG_up]
    rowEvent.minDepth[splice[
				EventType %in% c("AFE", "A5SS")
			], on = "EventName", c(df$sample[i]) := count_JG_down]					

	}
  
  rownames(rowEvent) = rowEvent$EventName

  Depth = as.matrix(round(rowEvent.Depth[, -1:-3]))
  Coverage = as.matrix(round(rowEvent.Coverage[,-1:-3]))
  minDepth = as.matrix(round(rowEvent.minDepth[, -1:-3]))
  mode(Depth) <- "integer"
  mode(Coverage) <- "integer"
  mode(minDepth) <- "integer"
  
  se = SummarizedExperiment::SummarizedExperiment(assays = S4Vectors::SimpleList(
			Depth = Depth, Coverage = Coverage, minDepth = minDepth
		), rowData = rowEvent, 
		colData = as.data.frame(colData[, -1, drop=FALSE], row.names = colData$sample))
  rownames(se) = SummarizedExperiment::rowData(se)$EventName
    
  return(se)
}


runFilter <- function(filterClass, filterType, filterVars, filterObject) {
# Internal function
  # filterClass: can be one of 'Annotation', 'Data', 'Runtime'
  # filterType:
    # - Annotation:
    # - Data:
        # - Depth: 1-minimum, 2-minCond, 3-pcTRUE
        # - Coverage: 1-minimum, 1a-minDepth, 2-minCond, 3-pcTRUE
    # - Runtime:
        # - UpDown: compares upstream vs downstream derived PIR/PSI
	
	filterResult = rep(TRUE, nrow(filterObject))
				
  if(filterClass == "Data") {
    if(filterType == "Depth") {
      message("Running Depth filter")
      colData = SummarizedExperiment::colData(filterObject)
      use_cond = ifelse("condition" %in% names(filterVars), TRUE, FALSE)
      if(use_cond == TRUE) {
        cond_vec = unlist(colData[, which(colnames(colData) == filterVars$condition)])
        cond_vars = unique(cond_vec)
      }
      depth = as.matrix(SummarizedExperiment::assay(filterObject, "Depth"))
      
      sum_res = rep(0, nrow(filterObject))
      if(use_cond == TRUE) {
        for(cond in cond_vars) {
          depth.subset = depth[, which(cond_vec == cond)]
          sum = rowSums(depth.subset > filterVars$minimum)
          sum_res = sum_res + ifelse(sum * 100 / ncol(depth.subset) >= filterVars$pcTRUE, 1, 0)
        }
        n_TRUE = ifelse(!is.null(names(filterVars)) && "minCond" %in% names(filterVars), filterVars$minCond, -1)
        if(n_TRUE == -1) n_TRUE = length(cond_vars)
        res = (sum_res >= n_TRUE)
      } else {
        sum = rowSums(depth > filterVars$minimum)
        res = ifelse(sum * 100 / ncol(depth) >= filterVars$pcTRUE, TRUE, FALSE)
      }
      if("EventTypes" %in% names(filterVars)) {
        res[!(SummarizedExperiment::rowData(filterObject)$EventType %in% filterVars$EventTypes)] = TRUE
      }
      return(res)
    } else if(filterType == "Coverage") {
      message("Running Coverage filter")
      colData = SummarizedExperiment::colData(filterObject)
      use_cond = ifelse(!is.null(names(filterVars)) && "condition" %in% names(filterVars), TRUE, FALSE)
      if(use_cond == TRUE) {
        cond_vec = unlist(colData[, which(colnames(colData) == filterVars$condition)])
        cond_vars = unique(cond_vec)
      }
      cov = as.matrix(SummarizedExperiment::assay(filterObject, "Coverage"))
      depth = as.matrix(SummarizedExperiment::assay(filterObject, "minDepth"))
      cov[depth < filterVars$minDepth] = 1    # do not test if depth below threshold
      
      sum_res = rep(0, nrow(filterObject))
      if(use_cond == TRUE) {
        for(cond in cond_vars) {
          cov.subset = cov[, which(cond_vec == cond)]
          sum = rowSums(cov.subset > filterVars$minimum)
          sum_res = sum_res + ifelse(sum * 100 / ncol(cov.subset) >= filterVars$pcTRUE, 1, 0)
        }
        n_TRUE = ifelse(!is.null(names(filterVars)) && "minCond" %in% names(filterVars), filterVars$minCond, -1)
        if(n_TRUE == -1) n_TRUE = length(cond_vars)
        res = (sum_res >= n_TRUE)
      } else {
        sum = rowSums(cov > filterVars$minimum)
        res = ifelse(sum * 100 / ncol(cov.subset) >= filterVars$pcTRUE, TRUE, FALSE)
      }
      res[!(SummarizedExperiment::rowData(filterObject)$EventType %in% filterVars$EventTypes)] = TRUE
      return(res)
    }
  } else if(filterClass == "Annotation") {
		return(filterResult)
  } else {
    return(filterResult)
  }
}


greplFilter = function(object, filterList) {
  # filterList is a list of filters
  # each filter is a list of variables
  
  assertthat::assert_that(is(object, "SummarizedExperiment"),
    msg = "object must be a SummarizedExperiment object returned using BuildFilterData()")
  
  keepEvent = rep(TRUE, nrow(object))
  
  if("filterClass" %in% names(filterList)) {
    # Treat as a single filter
    keepEvent = keepEvent & runFilter(filterList$filterClass, filterList$filterType,
      filterList$filterVars, object)
  } else {  
    # Treat as multiple filters
    for(fil in filterList) {
      if("filterClass" %in% names(fil)) {
      keepEvent = keepEvent & runFilter(fil$filterClass, fil$filterType,
        fil$filterVars, object)      
      }
    }
  }
  return(keepEvent)
}

#' @export
BuildSE = function(irf_fst_files, colData, IRMode = c("SpliceOverMax", "SpliceMax")) {
	# Builds all PSI-related data
	# Included: matrix for EventA or IR
	# Excluded: matrix for EventB or Splice(Over)Max
	# Up_Inc: upstream included event (IR upstream overhang / MXE / SE)
	# Down_Inc: downstream included event for IR/MXE/SE
	# Up_Exc, Down_Exc: upstream excluded event (i.e. downstream casette exon) for MXE only
		
	assertthat::assert_that(all(grepl("\\.irf.fst$", irf_fst_files)),
		msg = "irf_fst_files must end in '.irf.fst'")
	assertthat::assert_that(all(file.exists(irf_fst_files)),
		msg = "Some IRFinder fst files do not exist")
	IRMode = match.arg(IRMode)
	assertthat::assert_that(IRMode != "",
		msg = "IRMode must be either 'SpliceOverMax' (default) or 'SpliceMax'")
		
  df = data.frame(sample = colData[,1], base_name = gsub("\\.irf.fst$", "", irf_fst_files),
    irf_file = irf_fst_files, stringsAsFactors = FALSE)
  df$splice_file = paste0(df$base_name, ".splice.fst")
	# skinny annotation
	irf.anno.brief = as.data.table(fst::read.fst(df$irf_file[1]))
	setnames(irf.anno.brief, "Name", "EventName")
	irf.anno.brief[, EventType := "IR"]
	irf.anno.brief[, EventRegion := paste0(seqnames, ":", start, "-", end, "/", strand)]
	irf.anno.brief = irf.anno.brief[, c("EventName", "EventType", "EventRegion")]
  splice.anno.brief = as.data.table(fst::read.fst(df$splice_file[1], c("EventName", "EventType", "EventRegion")))
	
	rowEvent = rbind(irf.anno.brief, splice.anno.brief)
			
	rowEvent.Included = copy(rowEvent)
	rowEvent.Excluded = copy(rowEvent)
	
	rowEvent.Up_Inc = rowEvent[EventType %in% c("IR", "MXE", "SE")]
	rowEvent.Down_Inc = rowEvent[EventType %in% c("IR", "MXE", "SE")]
	rowEvent.Up_Exc = rowEvent[EventType %in% c("MXE")]		# for IR and SE, this defaults to rowEvent.Excluded
	rowEvent.Down_Exc = rowEvent[EventType %in% c("MXE")]

	for(i in seq_len(nrow(df))) {
    message(paste("Processing sample", i))
    irf = as.data.table(fst::read.fst(df$irf_file[i]))
    setnames(irf, "Name", "EventName")
    splice = as.data.table(fst::read.fst(df$splice_file[i]))
    
    rowEvent.Included[, c(df$sample[i]) := 0]
    rowEvent.Included[irf, on = "EventName", c(df$sample[i]) := IntronDepth]
    rowEvent.Included[splice[EventType %in% c("SE", "MXE")], 
			on = "EventName", c(df$sample[i]) := (count_Event1a + count_Event2a) / 2]
    rowEvent.Included[splice[!(EventType %in% c("SE", "MXE"))], 
			on = "EventName", c(df$sample[i]) := count_Event1a]
			
    rowEvent.Excluded[, c(df$sample[i]) := 0]
		if(IRMode == "SpliceOverMax") {
			rowEvent.Excluded[irf, on = "EventName", c(df$sample[i]) := SpliceOverMax]		
		} else {
			rowEvent.Excluded[irf, on = "EventName", c(df$sample[i]) := SpliceMax]				
		}
    rowEvent.Excluded[splice[EventType %in% c("MXE")], 
			on = "EventName", c(df$sample[i]) := (count_Event1b + count_Event2b) / 2]
    rowEvent.Excluded[splice[!(EventType %in% c("MXE"))], 
			on = "EventName", c(df$sample[i]) := count_Event1b]
		
		# Validity checking for IR, MXE, SE
    rowEvent.Up_Inc[, c(df$sample[i]) := 0]
    rowEvent.Up_Inc[irf[strand == "+"], on = "EventName", c(df$sample[i]) := ExonToIntronReadsLeft]
    rowEvent.Up_Inc[irf[strand == "-"], on = "EventName", c(df$sample[i]) := ExonToIntronReadsRight]
    rowEvent.Up_Inc[splice, on = "EventName", c(df$sample[i]) := count_Event1a]

    rowEvent.Down_Inc[, c(df$sample[i]) := 0]
    rowEvent.Down_Inc[irf[strand == "+"], on = "EventName", c(df$sample[i]) := ExonToIntronReadsRight]
    rowEvent.Down_Inc[irf[strand == "-"], on = "EventName", c(df$sample[i]) := ExonToIntronReadsLeft]
    rowEvent.Down_Inc[splice, on = "EventName", c(df$sample[i]) := count_Event2a]
		
    rowEvent.Up_Exc[splice, on = "EventName", c(df$sample[i]) := count_Event2a]
		rowEvent.Down_Exc[splice, on = "EventName", c(df$sample[i]) := count_Event2b]
	}
  
  # rownames(colData) = colData$sample
  rownames(rowData) = rowData$EventName
  # colData$sample = NULL
  Included = as.matrix(round(rowEvent.Included[, -1:-3]))
  Excluded = as.matrix(round(rowEvent.Excluded[, -1:-3]))
  mode(Included) <- "integer"
  mode(Excluded) <- "integer"
  
  se = SummarizedExperiment::SummarizedExperiment(assays = S4Vectors::SimpleList(
		Included = Included, Excluded = Excluded),
    rowData = rowEvent, colData = as.data.frame(colData[, -1, drop=FALSE], row.names = colData$sample))
  rownames(se) = SummarizedExperiment::rowData(se)$EventName
  
	S4Vectors::metadata(se)$Up_Inc = as.matrix(round(rowEvent.Up_Inc[, -1:-3]))
	S4Vectors::metadata(se)$Down_Inc = as.matrix(round(rowEvent.Down_Inc[, -1:-3]))
	S4Vectors::metadata(se)$Up_Exc = as.matrix(round(rowEvent.Up_Exc[, -1:-3]))
	S4Vectors::metadata(se)$Down_Exc = as.matrix(round(rowEvent.Down_Exc[, -1:-3]))
	
  mode(S4Vectors::metadata(se)$Up_Inc) <- "integer"
	mode(S4Vectors::metadata(se)$Down_Inc) <- "integer"
	mode(S4Vectors::metadata(se)$Up_Exc) <- "integer"
	mode(S4Vectors::metadata(se)$Down_Exc) <- "integer"
	
  return(se)
}





