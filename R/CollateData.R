#' @export
FindSamples <- function(sample_path, suffix = ".txt.gz", use_subdir = FALSE) {
    assertthat::assert_that(dir.exists(sample_path),
        msg = "Given path does not exist")
    
    files_found = list.files(pattern = paste0("\\", suffix, "$"),
        path = normalizePath(sample_path), full.names = TRUE, recursive = TRUE)
    if(length(files_found) > 0) {
      df = data.frame(sample = "", path = files_found)
      if(use_subdir) {
          df$sample = basename(dirname(df$path))
      } else {
          df$sample = sub(suffix,"",basename(df$path))
      }
      return(df)
    } else {
      return(NULL)
    }
}

#' Processes data from IRFinder output
#'
#' @param Experiment: A data frame containing the necessary information. The first column is the base name of the sample files. The second column is the sample name. All subsequent columns are assumed to be experimental conditions / annotation data (e.g. gender, age, treatment response, etc)
#' @param reference_path: THe path to the reference generated by BuildReference()
#' @param output_path: The path to the output generated by data collation.
#' @export
CollateData <- function(Experiment, reference_path, output_path, IRMode = c("SpliceOverMax", "SpliceMax"), 
  localHub = FALSE, samples_per_block = 16, BPPARAM = BiocParallel::bpparam()) {
    assertthat::assert_that("data.frame" %in% class(Experiment),
        msg = "Experiment object needs to be a data frame")
    assertthat::assert_that(ncol(Experiment) >= 2,
        msg = "Experiment needs to contain two columns containing (1) sample name and (2) IRFinder output")

    assertthat::assert_that(file.exists(file.path(reference_path, "settings.Rds")),
        msg = paste(file.path(reference_path, "settings.Rds"), "does not exist"))

    IRMode = match.arg(IRMode)
    assertthat::assert_that(IRMode != "",
      msg = "IRMode must be either 'SpliceOverMax' (default) or 'SpliceMax'")

		settings = readRDS(file.path(reference_path, "settings.Rds"))
		if(settings$ah_genome != "") {
			genome = FetchAH(settings$ah_genome, localHub = localHub)
		} else {
			genome = rtracklayer::TwoBitFile(file.path(reference_path, "resource", "genome.2bit"))
		}
    
    colnames(Experiment)[1:2] = c("sample", "path")
    # TODO: check each file within Experiment$path is valid
    
    # Create a subdirectory for each sample within output_path
    base_output_path = normalizePath(dirname(output_path))      # TODO check if this fails
    norm_output_path = file.path(base_output_path, basename(output_path))
    if(!dir.exists(norm_output_path)) {
        dir.create(norm_output_path)
    }
    temp_output_path = file.path(norm_output_path, "temp")
    if(!dir.exists(temp_output_path)) {
        dir.create(temp_output_path)
    }		
    if(!dir.exists(file.path(norm_output_path, "samples"))) {
        dir.create(file.path(norm_output_path, "samples"))
    }		


    df.internal = as.data.table(Experiment[,1:2])
    df.internal$paired = FALSE
    df.internal$strand = 0
    df.internal$depth = 0
    df.internal$mean_frag_size = 0
    df.internal$directionality_strength = 0
    df.internal$Intergenic_Fraction = 0
    df.internal$rRNA_Fraction = 0
    df.internal$NonPolyA_Fraction = 0
    df.internal$Mitochondrial_Fraction = 0
    df.internal$Unanno_Jn_Fraction = 0
    df.internal$Fraction_Splice_Reads = 0
    df.internal$Fraction_Span_Reads = 0

    fst::threads_fst(1)

    message("Compiling Sample Stats")
    df.internal = suppressWarnings(rbindlist(
      BiocParallel::bplapply(NxtIRF.SplitVector(seq_len(nrow(df.internal)), BPPARAM$workers),
        function(work, df.internal) {
          suppressPackageStartupMessages({
            library(data.table)
            library(stats)
          })
          block = df.internal[work]
          for(i in seq_len(length(work))) {
            stats = suppressWarnings(fread(block$path[i], skip = "BAM", 
							colClasses = c("character", "numeric")))
            direct = suppressWarnings(fread(block$path[i], skip = "Directionality", 
							colClasses = c("character", "numeric")))
            ROI = suppressWarnings(fread(block$path[i], skip = "ROIname"))
            ChrCov = suppressWarnings(fread(block$path[i], skip = "ChrCoverage"))
            junc = suppressWarnings(fread(block$path[i], skip = "JC_seqname"))
		
            if(stats$Value[3] == 0 & stats$Value[4] > 0) {
                block$paired[i] = TRUE
                block$depth[i] = stats$Value[4]
								block$mean_frag_size[i] = stats$Value[2] / stats$Value[4]
            } else if(stats$Value[3] > 0 && stats$Value[4] / stats$Value[3] / 1000) {
                block$paired[i] = TRUE
                block$depth[i] = stats$Value[4]
								block$mean_frag_size[i] = stats$Value[2] / stats$Value[4]
            } else {
                block$paired[i] = FALSE
                block$depth[i] = stats$Value[3]
								block$mean_frag_size[i] = stats$Value[2] / stats$Value[3]
            }
            block$strand[i] = direct$Value[9]
            
						# QC
						block$directionality_strength[i] = direct$Value[8]
						ROI$type = tstrsplit(ROI$ROIname, split="/")[[1]]
						block$Intergenic_Fraction[i] = sum(ROI$total_hits[ROI$type == "Intergenic"]) / block$depth[i]
						block$rRNA_Fraction[i] = sum(ROI$total_hits[ROI$type == "rRNA"]) / block$depth[i]
						block$NonPolyA_Fraction[i] = sum(ROI$total_hits[ROI$type == "NonPolyA"]) / block$depth[i]
						block$Mitochondrial_Fraction[i] = sum(ChrCov$total[ChrCov$ChrCoverage_seqname %in% c("M", "MT")]) / block$depth[i]
						block$Unanno_Jn_Fraction[i] = sum(junc$total[junc$strand == "."]) / sum(junc$total)
						block$Fraction_Splice_Reads[i] = sum(junc$total) / block$depth[i]

            spans = suppressWarnings(fread(block$path[i], skip = "SP_seqname"))        
						block$Fraction_Span_Reads[i] = sum(spans$total) / block$depth[i]
          }
          return(block)
        }, df.internal = df.internal, BPPARAM = BPPARAM
      )
    ))
    
    if(any(df.internal$strand == 0)) {
        runStranded = FALSE
    } else {
        runStranded = TRUE
    }
    
    # Compile junctions and IR lists first, save to temp files
    message("Compiling Junction List")       
    # Compile junc.common via merge
    junc.list = suppressWarnings(BiocParallel::bplapply(NxtIRF.SplitVector(seq_len(nrow(df.internal)), BPPARAM$workers),
      function(work, df.internal, temp_output_path) {
        suppressPackageStartupMessages({
          library(data.table)
          library(stats)
        })
        block = df.internal[work]
        junc.segment = NULL
        for(i in seq_len(length(work))) {
          junc = suppressWarnings(as.data.table(fread(block$path[i], skip = "JC_seqname")))
          setnames(junc, "JC_seqname", "seqnames")
          if(is.null(junc.segment)) {
              junc.segment = junc[,1:4]
          } else {
              junc.segment = merge(junc.segment, junc[,1:4], all = TRUE)
          }
        # Write temp file
            fst::write.fst(as.data.frame(junc), 
                file.path(temp_output_path, paste(block$sample[i], "junc.fst.tmp", sep=".")))        
        }
        return(junc.segment)
      }, df.internal = df.internal, temp_output_path = temp_output_path, BPPARAM = BPPARAM
    ))
    junc.common = NULL
    for(i in seq_len(length(junc.list))) {
      if(is.null(junc.common)) {
        junc.common = junc.list[[i]]
      } else {
        junc.common = merge(junc.common, junc.list[[i]], all = TRUE, by = colnames(junc.common))
      }
    }
    rm(junc.list)
    gc()
    message("Compiling Intron Retention List")    
    irf.list = suppressWarnings(BiocParallel::bplapply(NxtIRF.SplitVector(seq_len(nrow(df.internal)), BPPARAM$workers),
      function(work, df.internal, temp_output_path, runStranded, semi_join.DT) {
        suppressPackageStartupMessages({
          library(data.table)
          library(stats)
        })
        block = df.internal[work]
        irf.segment = NULL
        for(i in seq_len(length(work))) {
        
        # Compile IRFinder based on strand
          if(!runStranded) {
            irf = suppressWarnings(as.data.table(fread(block$path[i], skip = "Nondir_")))
            setnames(irf, c("Nondir_Chr", "Start", "End", "Strand"), c("seqnames","start","end", "strand"))
          } else {
            irf = suppressWarnings(as.data.table(fread(block$path[i], skip = "Dir_Chr")))
            setnames(irf, c("Dir_Chr", "Start", "End", "Strand"), c("seqnames","start","end", "strand"))          
          }
          if(is.null(irf.segment)) {
              irf.segment = irf[,1:6]
          } else {
              irf.segment = semi_join.DT(irf.segment, irf[,1:6], by = colnames(irf.segment))
          }
          fst::write.fst(as.data.frame(irf), 
            file.path(temp_output_path, paste(block$sample[i], "irf.fst.tmp", sep=".")))
        }
        return(irf.segment)
      }, df.internal = df.internal, temp_output_path = temp_output_path, 
        runStranded = runStranded, semi_join.DT = semi_join.DT, BPPARAM = BPPARAM
    ))
    irf.common = NULL
    for(i in seq_len(length(irf.list))) {
      if(is.null(irf.common)) {
        irf.common = irf.list[[i]]
      } else {
        irf.common = merge(irf.common, irf.list[[i]], all = TRUE, by = colnames(irf.common))
      }
    }
    rm(irf.list)
    gc()

    irf.common[, start := start + 1]
    junc.common[, start := start + 1]

# Reassign +/- based on junctions.fst annotation
    # Annotate junctions
    message("Tidying up splice junctions and intron retentions")
    
    candidate.introns = as.data.table(fst::read.fst(file.path(reference_path, "fst", "junctions.fst")))

    junc.strand = unique(candidate.introns[, c("seqnames", "start", "end", "strand")])

    junc.common[, strand := NULL]
    junc.common = unique(junc.common)
    junc.common = merge(junc.common, junc.strand, all = TRUE, by = c("seqnames", "start", "end"))
    junc.common[is.na(strand), strand := "*"]

    left.gr = GenomicRanges::GRanges(seqnames = junc.common$seqnames, 
        ranges = IRanges::IRanges(start = junc.common$start, end = junc.common$start + 1), strand = "+")
    right.gr = GenomicRanges::GRanges(seqnames = junc.common$seqnames, 
        ranges = IRanges::IRanges(start = junc.common$end - 1, end = junc.common$end), strand = "+")
        
    left.seq = BSgenome::getSeq(genome, left.gr)
    right.seq = BSgenome::getSeq(genome, right.gr)

    junc.common$motif_pos = paste0(as.character(left.seq), as.character(right.seq))
    junc.common$motif_infer_strand = "n"
    junc.common[ motif_pos %in% c("GTAG", "GCAG", "ATAC", "ATAG"), motif_infer_strand := "+"]
    junc.common[ motif_pos %in% c("CTAC", "CTGC", "GTAT", "CTAT"), motif_infer_strand := "-"]
    junc.common[ motif_pos %in% c("GTAC"), motif_infer_strand := "n"]       # Do not accept un-annotated GTACs - too confusing
    # Exclude non-splice motifs (that are also not annotated - i.e. strand == "*")
    junc.common = junc.common[motif_infer_strand != "n" | strand != "*"]

    # Use motif_infer_strand (only for *)
    junc.common[strand == "*", strand := motif_infer_strand]
    junc.common$motif_infer_strand = NULL
    
    # Should splicing across gene groups be allowed? Exclude
    Genes = GenomicRanges::makeGRangesFromDataFrame(
        fst::read.fst(file.path(reference_path, "fst", "Genes.fst"))
    )

    # Exclude distant splice events:

    # Genes.Group.stranded = as.data.table(
        # GenomicRanges::reduce(c(Genes, GenomicRanges::flank(Genes, 5000),
        # GenomicRanges::flank(Genes, 5000, start = FALSE))
    # ))
    # setorder(Genes.Group.stranded, seqnames, start, strand)
    # Genes.Group.stranded[, gene_group_stranded := .I]
    
    # junc.common.left = copy(junc.common)
    # junc.common.left[, start := start - 1]
    # junc.common.left[, end := start + 1]
    # OL = suppressWarnings(
        # GenomicRanges::findOverlaps(
            # GenomicRanges::makeGRangesFromDataFrame(as.data.frame(junc.common.left)), 
            # GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Genes.Group.stranded))
        # )
    # )
    # junc.common$gene_group_left[OL@from] = Genes.Group.stranded$gene_group_stranded[OL@to]

    # junc.common.right = copy(junc.common)
    # junc.common.right[, end := end + 1]
    # junc.common.right[, start := end - 1]
    # OL = suppressWarnings(
        # GenomicRanges::findOverlaps(
            # GenomicRanges::makeGRangesFromDataFrame(as.data.frame(junc.common.right)), 
            # GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Genes.Group.stranded))
        # )
    # )
    # junc.common$gene_group_right[OL@from] = Genes.Group.stranded$gene_group_stranded[OL@to]
        

    # junc.common = junc.common[gene_group_left == gene_group_right & !is.na(gene_group_left)]
    # junc.common$gene_group_left = NULL
    # junc.common$gene_group_right = NULL
    
    # Assign region names to junctions:
    junc.common[, Event := paste0(seqnames, ":", start, "-", end, "/", strand)]
    
    candidate.introns[, transcript_biotype_2 := transcript_biotype]
    candidate.introns[!(transcript_biotype %in% c("protein_coding", "processed_transcript",
        "lincRNA", "antisense", "nonsense_mediated_decay")), transcript_biotype_2 := "other"]

    candidate.introns[, transcript_biotype_2 := factor(transcript_biotype_2, c("protein_coding", "processed_transcript",
        "lincRNA", "antisense", "other", "nonsense_mediated_decay"), ordered = TRUE)]
        
    if("transcript_support_level" %in% colnames(candidate.introns)) {
        setorder(candidate.introns, transcript_biotype_2, transcript_support_level)
    } else {
        setorder(candidate.introns, transcript_biotype_2)    
    }
    introns.unique = unique(candidate.introns, by = c("seqnames", "start", "end", "width", "strand"))
    setorder(introns.unique, seqnames, start, end, strand)

    junc.annotation = introns.unique[junc.common, 
        c("seqnames", "start", "end", "strand", "transcript_id", "intron_number", "gene_name", "gene_id", "transcript_biotype"),
        on = c("seqnames", "start", "end", "strand")]
    
    # Use Exon Groups file to designate exon groups to all junctions
    Exon.Groups = GenomicRanges::makeGRangesFromDataFrame(
        fst::read.fst(file.path(reference_path, "fst", "Exons.groups.fst")),
        keep.extra.columns = TRUE)
    
    # Always calculate stranded for junctions
    # if(!runStranded) {
        # Exon.Groups = Exon.Groups[strand(Exon.Groups) == "*"]
    # } else {
        # Exon.Groups = Exon.Groups[strand(Exon.Groups) != "*"]    
    # }
    Exon.Groups.S = Exon.Groups[GenomicRanges::strand(Exon.Groups) != "*"]    
    
    junc.common.left = copy(junc.common)
    junc.common.left[, start := start - 1]
    junc.common.left[, end := start + 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(junc.common.left)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    junc.common$gene_group_left[OL@from] = Exon.Groups.S$gene_group[OL@to]
    junc.common$exon_group_left[OL@from] = Exon.Groups.S$exon_group[OL@to]

    junc.common.right = copy(junc.common)
    junc.common.right[, end := end + 1]
    junc.common.right[, start := end - 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(junc.common.right)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    junc.common$gene_group_right[OL@from] = Exon.Groups.S$gene_group[OL@to]
    junc.common$exon_group_right[OL@from] = Exon.Groups.S$exon_group[OL@to]
    
    junc.common[, JG_up := ""]
    junc.common[, JG_down := ""]
    junc.common[strand == "+" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        JG_up := paste(gene_group_left, exon_group_left, sep="_")]
    junc.common[strand == "-" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        JG_up := paste(gene_group_right, exon_group_right, sep="_")]
    junc.common[strand == "+" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        JG_down := paste(gene_group_right, exon_group_right, sep="_")]
    junc.common[strand == "-" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        JG_down := paste(gene_group_left, exon_group_left, sep="_")]

    junc.common$gene_group_left = NULL
    junc.common$gene_group_right = NULL
    junc.common$exon_group_left = NULL
    junc.common$exon_group_right = NULL
    
    irf.common.left = copy(irf.common)
    irf.common.left[, start := start - 1]
    irf.common.left[, end := start + 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(irf.common.left)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    irf.common$gene_group_left[OL@from] = Exon.Groups.S$gene_group[OL@to]
    irf.common$exon_group_left[OL@from] = Exon.Groups.S$exon_group[OL@to]

    irf.common.right = copy(irf.common)
    irf.common.right[, end := end + 1]
    irf.common.right[, start := end - 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(irf.common.right)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    irf.common$gene_group_right[OL@from] = Exon.Groups.S$gene_group[OL@to]
    irf.common$exon_group_right[OL@from] = Exon.Groups.S$exon_group[OL@to]
    
    irf.common[, JG_up := ""]
    irf.common[, JG_down := ""]
    irf.common[strand == "+" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        JG_up := paste(gene_group_left, exon_group_left, sep="_")]
    irf.common[strand == "-" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        JG_up := paste(gene_group_right, exon_group_right, sep="_")]
    irf.common[strand == "+" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        JG_down := paste(gene_group_right, exon_group_right, sep="_")]
    irf.common[strand == "-" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        JG_down := paste(gene_group_left, exon_group_left, sep="_")]

    irf.common$gene_group_left = NULL
    irf.common$gene_group_right = NULL
    irf.common$exon_group_left = NULL
    irf.common$exon_group_right = NULL
    
    if(!runStranded) {
        Exon.Groups = Exon.Groups[GenomicRanges::strand(Exon.Groups) == "*"]
    } else {
        Exon.Groups = Exon.Groups[GenomicRanges::strand(Exon.Groups) != "*"]    
    }
    irf.common.left = copy(irf.common)
    irf.common.left[, start := start - 1]
    irf.common.left[, end := start + 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(irf.common.left)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    irf.common$gene_group_left[OL@from] = Exon.Groups.S$gene_group[OL@to]
    irf.common$exon_group_left[OL@from] = Exon.Groups.S$exon_group[OL@to]

    irf.common.right = copy(irf.common)
    irf.common.right[, end := end + 1]
    irf.common.right[, start := end - 1]
    OL = suppressWarnings(
        GenomicRanges::findOverlaps(
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(irf.common.right)), 
            GenomicRanges::makeGRangesFromDataFrame(as.data.frame(Exon.Groups.S))
        )
    )
    irf.common$gene_group_right[OL@from] = Exon.Groups.S$gene_group[OL@to]
    irf.common$exon_group_right[OL@from] = Exon.Groups.S$exon_group[OL@to]
    
    irf.common[, IRG_up := ""]
    irf.common[, IRG_down := ""]
    irf.common[strand == "+" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        IRG_up := paste(gene_group_left, exon_group_left, sep="_")]
    irf.common[strand == "-" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        IRG_up := paste(gene_group_right, exon_group_right, sep="_")]
    irf.common[strand == "+" & !is.na(gene_group_right) & !is.na(exon_group_right), 
        IRG_down := paste(gene_group_right, exon_group_right, sep="_")]
    irf.common[strand == "-" & !is.na(gene_group_left) & !is.na(exon_group_left), 
        IRG_down := paste(gene_group_left, exon_group_left, sep="_")]
    irf.common$gene_group_left = NULL
    irf.common$gene_group_right = NULL
    irf.common$exon_group_left = NULL
    irf.common$exon_group_right = NULL

    irf.common[, EventRegion := paste0(seqnames, ":", start, "-", end, "/", strand)]

    Splice.Anno = as.data.table(fst::read.fst(file.path(reference_path, "fst", "Splice.fst")))
    candidate.introns[, Event1a := Event]
    candidate.introns[, Event2a := Event]
    Splice.Anno[candidate.introns, on = "Event1a", up_1a := paste(i.gene_group_stranded, 
        i.exon_group_stranded_upstream, sep="_")]
    Splice.Anno[candidate.introns, on = "Event1a", down_1a := paste(i.gene_group_stranded, 
        i.exon_group_stranded_downstream, sep="_")]
    Splice.Anno[candidate.introns, on = "Event2a", down_2a := paste(i.gene_group_stranded, 
        i.exon_group_stranded_downstream, sep="_")]
    
    Splice.Anno[EventType %in% c("MXE", "SE", "ALE", "A3SS"),
        JG_up := up_1a]
    Splice.Anno[EventType %in% c("SE", "AFE", "A5SS"),
        JG_down := down_1a]
    Splice.Anno[EventType %in% c("MXE"),
        JG_down := down_2a]
    
    Splice.Anno$up_1a = NULL
    Splice.Anno$down_1a = NULL
    Splice.Anno$down_2a = NULL
    Splice.Anno[, strand := tstrsplit(Event1a, split="/")[[2]]]
    
    rm(candidate.introns, introns.unique)
    gc()

	# Save irf.common, Splice.Anno
	fst::write_fst(as.data.frame(junc.common), file.path(norm_output_path, "Junc.fst"))
	fst::write_fst(as.data.frame(irf.common), file.path(norm_output_path, "IR.fst"))
	fst::write_fst(as.data.frame(Splice.Anno), file.path(norm_output_path, "Splice.fst"))

	# make rowEvent here
	irf.anno.brief = irf.common[, c("Name", "EventRegion")]
	setnames(irf.anno.brief, "Name", "EventName")
	irf.anno.brief[, EventType := "IR"]
	irf.anno.brief = irf.anno.brief[, c("EventName", "EventType", "EventRegion")]
	
	splice.anno.brief = Splice.Anno[, c("EventName", "EventType", "EventRegion")]
	
	rowEvent = rbind(irf.anno.brief, splice.anno.brief)	
  item.todo = c("Included", "Excluded", "Depth", "Coverage", "minDepth", "Up_Inc", "Down_Inc", "Up_Exc", "Down_Exc")

  fst::write.fst(rowEvent, file.path(norm_output_path, "rowEvent.fst"))

  message("Generating NxtIRF FST files")
	
  n_jobs = max(ceiling(nrow(df.internal) / samples_per_block), BPPARAM$workers)
  jobs = NxtIRF.SplitVector(seq_len(nrow(df.internal)), n_jobs)	
	
	suppressWarnings(BiocParallel::bplapply(seq_len(n_jobs),
		function(x, jobs, df.internal, norm_output_path) {
			suppressPackageStartupMessages({
				library(data.table)
				library(stats)
			})
      
      # Read this from fst file
      rowEvent = as.data.table(fst::read.fst(file.path(norm_output_path, "rowEvent.fst")))
      junc.common = as.data.table(fst::read.fst(file.path(norm_output_path, "Junc.fst")))
      irf.common = as.data.table(fst::read.fst(file.path(norm_output_path, "IR.fst")))
      Splice.Anno = as.data.table(fst::read.fst(file.path(norm_output_path, "Splice.fst")))
      
			work = jobs[[x]]
			block = df.internal[work]
			
			Included = copy(rowEvent)
			Excluded = copy(rowEvent)
			Depth = copy(rowEvent)
			Coverage = copy(rowEvent)
			minDepth = copy(rowEvent)
			
			Up_Inc = rowEvent[EventType %in% c("IR", "MXE", "SE")]
			Down_Inc = rowEvent[EventType %in% c("IR", "MXE", "SE")]
			Up_Exc = rowEvent[EventType %in% c("MXE")]		# for IR and SE, this defaults to rowEvent.Excluded
			Down_Exc = rowEvent[EventType %in% c("MXE")]		
			
			for(i in seq_len(length(work))) {
				junc = as.data.table(
						fst::read.fst(file.path(norm_output_path, "temp", paste(block$sample[i], "junc.fst.tmp", sep=".")))
				)
				junc[, start := start + 1]
				junc$strand = NULL

				junc = junc[junc.common, on = colnames(junc.common)[1:3]]
				if(block$strand[i] == 0) {
						junc$count = junc$total    
				} else if(df.internal$strand[i] == -1) {
						junc$count = 0
						junc[strand == "+", count := neg]
						junc[strand == "-", count := pos]
						junc[strand == "*", count := total]
				} else {
						junc$count = 0
						junc[strand == "+", count := pos]
						junc[strand == "-", count := neg]
						junc[strand == "*", count := total]    
				}
				junc[is.na(count), count := 0]
				junc = junc[,c("seqnames", "start", "end", "strand", "Event", "count")]
				junc = cbind(junc, junc.common[, c("JG_up", "JG_down")])
				junc[, SO_L := 0]
				junc[, SO_R := 0]
				junc[JG_up != "" & strand == "+", SO_L := sum(count), by = "JG_up"]
				junc[JG_down != "" & strand == "+", SO_R := sum(count), by = "JG_down"]
				junc[JG_up != "" & strand == "-", SO_R := sum(count), by = "JG_up"]
				junc[JG_down != "" & strand == "-", SO_L := sum(count), by = "JG_down"]
				
				fst::write.fst(as.data.frame(junc), 
						file.path(norm_output_path, "samples", paste(block$sample[i], "junc.fst", sep=".")))

				splice = copy(Splice.Anno)
				
				splice[, count_Event1a := 0]
				splice[!is.na(Event1a), count_Event1a := junc$count[match(Event1a, junc$Event)]]
				splice[is.na(count_Event1a), count_Event1a := 0]
				splice[, count_Event2a := 0]
				splice[!is.na(Event2a), count_Event2a := junc$count[match(Event2a, junc$Event)]]
				splice[is.na(count_Event2a), count_Event2a := 0]
				splice[, count_Event1b := 0]
				splice[!is.na(Event1b), count_Event1b := junc$count[match(Event1b, junc$Event)]]
				splice[is.na(count_Event1b), count_Event1b := 0]
				splice[, count_Event2b := 0]
				splice[!is.na(Event2b), count_Event2b := junc$count[match(Event2b, junc$Event)]]
				splice[is.na(count_Event2b), count_Event2b := 0]

				splice[, count_JG_up := 0]
				splice[!is.na(JG_up) & strand == "+", count_JG_up := junc$SO_L[match(JG_up, junc$JG_up)]]
				splice[!is.na(JG_up) & strand == "-", count_JG_up := junc$SO_R[match(JG_up, junc$JG_up)]]
				splice[is.na(count_JG_up), count_JG_up := 0]
				splice[, count_JG_down := 0]
				splice[!is.na(JG_down) & strand == "-", count_JG_down := junc$SO_L[match(JG_down, junc$JG_down)]]
				splice[!is.na(JG_down) & strand == "+", count_JG_down := junc$SO_R[match(JG_down, junc$JG_down)]]
				splice[is.na(count_JG_down), count_JG_down := 0]

				# Splice participation: sum of two events compared to JG_up / JG_down
				splice[, partic_up := 0]
				splice[, partic_down := 0]

				splice[EventType %in% c("MXE", "SE", "ALE", "A3SS"), partic_up := count_Event1a + count_Event1b]
				splice[EventType %in% c("MXE"), partic_down := count_Event2a + count_Event2b]
				splice[EventType %in% c("SE"), partic_down := count_Event2a + count_Event1b]
				splice[EventType %in% c("AFE", "A5SS"), partic_down := count_Event1a + count_Event1b]

				# Splice coverage = participation / max_JG
				
				splice[, cov_up := 0]
				splice[count_JG_up > 0, cov_up := partic_up / count_JG_up]
				splice[, cov_down := 0]
				splice[count_JG_down > 0, cov_down := partic_down / count_JG_down]
				splice[EventType %in% c("MXE", "SE") & cov_up < cov_down, coverage := cov_up]
				splice[EventType %in% c("MXE", "SE") & cov_up >= cov_down, coverage := cov_down]
				splice[EventType %in% c("ALE", "A3SS"), coverage := cov_up]
				splice[EventType %in% c("AFE", "A5SS"), coverage := cov_down]
				
				irf = as.data.table(
						fst::read.fst(file.path(norm_output_path, "temp", paste(block$sample[i], "irf.fst.tmp", sep=".")))
				)
				irf[, start := start + 1]
				irf = irf[irf.common, on = colnames(irf.common)[1:6], EventRegion := i.EventRegion]
				
				# Extra statistics:
				irf[, SpliceMax := 0]
				irf[SpliceLeft >= SpliceRight, SpliceMax := SpliceLeft]
				irf[SpliceLeft < SpliceRight, SpliceMax := SpliceRight]

				irf[junc, on = c("seqnames", "start", "end", "strand"), SpliceOverLeft := SO_L]
				irf[junc, on = c("seqnames", "start", "end", "strand"), SpliceOverRight := SO_R]
				irf[SpliceOverLeft >= SpliceOverRight, SpliceOverMax := SpliceOverLeft]
				irf[SpliceOverLeft < SpliceOverRight, SpliceOverMax := SpliceOverRight]
				
				irf[, IROratio := 0]
				irf[IntronDepth < 1 & IntronDepth > 0 & (Coverage + SpliceOverMax) > 0, IROratio := Coverage / (Coverage + SpliceOverMax)]
				irf[IntronDepth >= 1, IROratio := IntronDepth / (IntronDepth + SpliceOverMax)]

				irf[, TotalDepth := IntronDepth + SpliceOverMax]

				splice.no_region = splice[!(EventRegion %in% irf$EventRegion)]
				splice.no_region[, Depth1a := irf$TotalDepth[match(Event1a, irf$EventRegion)]]
				splice.no_region[, Depth2a := irf$TotalDepth[match(Event2a, irf$EventRegion)]]
				splice.no_region[, Depth1b := irf$TotalDepth[match(Event1b, irf$EventRegion)]]
				splice.no_region[, Depth2b := irf$TotalDepth[match(Event2b, irf$EventRegion)]]
				splice.no_region[, Depth := 0]
				splice.no_region[count_JG_up > count_JG_down, Depth := count_JG_up]
				splice.no_region[count_JG_up <= count_JG_down, Depth := count_JG_down]
				splice.no_region[is.na(Depth1a), Depth1a := 0]
				splice.no_region[is.na(Depth1b), Depth1b := 0]
				splice.no_region[is.na(Depth2a), Depth2a := 0]
				splice.no_region[is.na(Depth2b), Depth2b := 0]
				splice.no_region[Depth1a > Depth2a, DepthA := Depth1a]
				splice.no_region[Depth1b > Depth2b, DepthB := Depth1b]
				splice.no_region[Depth1a <= Depth2a, DepthA := Depth2a]
				splice.no_region[Depth1b <= Depth2b, DepthB := Depth2b]
				splice.no_region[DepthA > DepthB, Depth := DepthA]
				splice.no_region[DepthA <= DepthB, Depth := DepthB]

				splice[, TotalDepth := 0]
				splice[irf, on = "EventRegion", TotalDepth := i.TotalDepth]
				splice[splice.no_region, on = "EventName", TotalDepth := i.Depth]

				fst::write.fst(as.data.frame(splice), 
						file.path(norm_output_path, "samples", paste(block$sample[i], "splice.fst", sep=".")))
				
				fst::write.fst(as.data.frame(irf),
						file.path(norm_output_path, "samples", paste(block$sample[i], "irf.fst", sep=".")))
						
				file.remove(file.path(norm_output_path, "temp", paste(block$sample[i], "junc.fst.tmp", sep=".")))
				file.remove(file.path(norm_output_path, "temp", paste(block$sample[i], "irf.fst.tmp", sep=".")))
				
				# Do BuildSE here
				setnames(irf, "Name", "EventName")
				# Included
				Included[, c(block$sample[i]) := c(
					irf$IntronDepth, 
					0.5 * (splice$count_Event1a[splice$EventType %in% c("SE", "MXE")] + 
						splice$count_Event2a[splice$EventType %in% c("SE", "MXE")]),
					splice$count_Event1a[!splice$EventType %in% c("SE", "MXE")]
				)]
				
				if(IRMode == "SpliceOverMax") {
					Excluded[, c(block$sample[i]) := c(
						irf$SpliceOverMax,
						0.5 * (splice$count_Event1b[splice$EventType %in% c("MXE")] + 
							splice$count_Event2b[splice$EventType %in% c("MXE")]),
						splice$count_Event1b[!splice$EventType %in% c("MXE")]
					)]
				} else {
					Excluded[, c(block$sample[i]) := c(
						irf$SpliceMaxMax,
						0.5 * (splice$count_Event1b[splice$EventType %in% c("MXE")] + 
							splice$count_Event2b[splice$EventType %in% c("MXE")]),
						splice$count_Event1b[!splice$EventType %in% c("MXE")]
					)]      
				}

				# Validity checking for IR, MXE, SE
				irf[strand == "+", Up_Inc := ExonToIntronReadsLeft]
				irf[strand == "-", Up_Inc := ExonToIntronReadsRight]
				irf[strand == "+", Down_Inc := ExonToIntronReadsRight]
				irf[strand == "-", Down_Inc := ExonToIntronReadsLeft]
				
				Up_Inc[, c(block$sample[i]) := c(irf$Up_Inc, splice$count_Event1a[splice$EventType %in% c("MXE", "SE")])]
				Down_Inc[, c(block$sample[i]) := c(irf$Down_Inc, splice$count_Event2a[splice$EventType %in% c("MXE", "SE")])]
				
				Up_Exc[, c(block$sample[i]) := splice$count_Event2a[splice$EventType %in% c("MXE")]]
				Down_Exc[, c(block$sample[i]) := splice$count_Event2b[splice$EventType %in% c("MXE")]]
				
				Depth[, c(block$sample[i]) := c(irf$TotalDepth, splice$TotalDepth)]
				Coverage[, c(block$sample[i]) := c(irf$Coverage, splice$coverage)]
				
				splice[EventType %in% c("MXE", "SE") & cov_up < cov_down, minDepth := count_JG_up]
				splice[EventType %in% c("MXE", "SE") & cov_up >= cov_down, minDepth := count_JG_down]
				splice[EventType %in% c("ALE", "A3SS"), minDepth := count_JG_up]
				splice[EventType %in% c("AFE", "A5SS"), minDepth := count_JG_down]
				
				minDepth[, c(block$sample[i]) := c(
					irf$IntronDepth,
					splice$minDepth)]
			} # end FOR loop
			
			# Write BuildSE temp files
			value = t(as.matrix(Included[, -c(1:3)]))
			fwrite(as.data.frame(value), file.path(norm_output_path, "temp", 
				paste("Included", as.character(x), "txt.gz", sep=".")), 
				col.names = FALSE, row.names = FALSE)
			value = t(as.matrix(Excluded[, -c(1:3)]))
			fwrite(as.data.frame(value), file.path(norm_output_path, "temp", 
				paste("Excluded", as.character(x), "txt.gz", sep=".")), 
				col.names = FALSE, row.names = FALSE)
			value = t(as.matrix(Depth[, -c(1:3)]))
			fwrite(as.data.frame(value), file.path(norm_output_path, "temp", 
				paste("Depth", as.character(x), "txt.gz", sep=".")), 
				col.names = FALSE, row.names = FALSE)
			value = t(as.matrix(Coverage[, -c(1:3)]))
			fwrite(as.data.frame(value), file.path(norm_output_path, "temp", 
				paste("Coverage", as.character(x), "txt.gz", sep=".")), 
				col.names = FALSE, row.names = FALSE)
			value = t(as.matrix(minDepth[, -c(1:3)]))
			fwrite(as.data.frame(value), file.path(norm_output_path, "temp", 
				paste("minDepth", as.character(x), "txt.gz", sep=".")), 
				col.names = FALSE, row.names = FALSE)
			value = t(as.matrix(Up_Inc[, -c(1:3)]))
			fwrite(as.data.frame(value), file.path(norm_output_path, "temp", 
				paste("Up_Inc", as.character(x), "txt.gz", sep=".")), 
				col.names = FALSE, row.names = FALSE)
			value = t(as.matrix(Down_Inc[, -c(1:3)]))
			fwrite(as.data.frame(value), file.path(norm_output_path, "temp", 
				paste("Down_Inc", as.character(x), "txt.gz", sep=".")), 
				col.names = FALSE, row.names = FALSE)
			value = t(as.matrix(Up_Exc[, -c(1:3)]))
			fwrite(as.data.frame(value), file.path(norm_output_path, "temp", 
				paste("Up_Exc", as.character(x), "txt.gz", sep=".")), 
				col.names = FALSE, row.names = FALSE)
			value = t(as.matrix(Down_Exc[, -c(1:3)]))
			fwrite(as.data.frame(value), file.path(norm_output_path, "temp", 
				paste("Down_Exc", as.character(x), "txt.gz", sep=".")), 
				col.names = FALSE, row.names = FALSE)
			
		}, df.internal = df.internal, jobs = jobs, 
			norm_output_path = norm_output_path, BPPARAM = BPPARAM
	))
  
  message("Building Final SummarizedExperiment Object")
	
  for(item in item.todo) {
		file.df = data.frame(file = list.files(pattern = item, path = temp_output_path))
		file.df$index = as.numeric(tstrsplit(file.df, split=".", fixed = TRUE)[[2]])
		file.df = file.df %>% dplyr::arrange(index)
		mat = NULL
		for(x in seq_len(n_jobs)) {
			temp = t(fread(file.path(temp_output_path, file.df$file[x]), data.table = FALSE))
			colnames(temp) = df.internal$sample[jobs[[x]]]
			mat = cbind(mat, temp)
			file.remove(file.path(temp_output_path, file.df$file[x]))
		}
    outfile = file.path(norm_output_path, paste(item, "fst", sep="."))
    fst::write.fst(as.data.frame(mat), outfile)
  }
  
  fst::threads_fst(parallel::detectCores())

  message("NxtIRF Collation Finished")
}

#' @export
MakeSE = function(colData, fst_path) {

  item.todo = c("rowEvent", "Included", "Excluded", "Depth", "Coverage", 
    "minDepth", "Up_Inc", "Down_Inc", "Up_Exc", "Down_Exc")
  files.todo = file.path(normalizePath(fst_path), paste(item.todo, "fst", sep="."))
  assertthat::assert_that(all(file.exists(files.todo)),
    msg = "FST File generation appears incomplete. Suggest run CollateData() again")

  colnames(colData)[1] = "sample"
  
  rowData = fst::read.fst(files.todo[1])
  Included = as.matrix(fst::read.fst(files.todo[2], columns = colData$sample))
  Excluded = as.matrix(fst::read.fst(files.todo[3], columns = colData$sample))
  Depth = as.matrix(fst::read.fst(files.todo[4], columns = colData$sample))
  Coverage = as.matrix(fst::read.fst(files.todo[5], columns = colData$sample))
  minDepth = as.matrix(fst::read.fst(files.todo[6], columns = colData$sample))
  Up_Inc = as.matrix(fst::read.fst(files.todo[7], columns = colData$sample))
  Down_Inc = as.matrix(fst::read.fst(files.todo[8], columns = colData$sample))
  Up_Exc = as.matrix(fst::read.fst(files.todo[9], columns = colData$sample))
  Down_Exc = as.matrix(fst::read.fst(files.todo[10], columns = colData$sample))

  mode(Included) <- "integer"
  mode(Excluded) <- "integer"
  mode(Up_Inc) <- "integer"
  mode(Down_Inc) <- "integer"
  mode(Up_Exc) <- "integer"
  mode(Down_Exc) <- "integer"
  
  se = SummarizedExperiment::SummarizedExperiment(assays = S4Vectors::SimpleList(
		Included = Included, Excluded = Excluded),
    rowData = rowData, colData = as.data.frame(colData[, -1, drop=FALSE], row.names = colData$sample))
  rownames(se) = SummarizedExperiment::rowData(se)$EventName

  S4Vectors::metadata(se)$Up_Inc = Up_Inc
	S4Vectors::metadata(se)$Down_Inc = Down_Inc
	S4Vectors::metadata(se)$Up_Exc = Up_Exc
	S4Vectors::metadata(se)$Down_Exc = Down_Exc

  se.filter = SummarizedExperiment::SummarizedExperiment(assays = S4Vectors::SimpleList(
			Depth = Depth, Coverage = Coverage, minDepth = minDepth
		), rowData = rowData, 
		colData = as.data.frame(colData[, -1, drop=FALSE], row.names = colData$sample))
  rownames(se.filter) = SummarizedExperiment::rowData(se.filter)$EventName
  
  final = list(se = se, se.filter = se.filter)
  return(final)
}


#' @export
BuildSE = function(irf_fst_files, colData, fst_path = file.path(dirname(irf_fst_files[1]), "Collated"),
  IRMode = c("SpliceOverMax", "SpliceMax"), samples_per_block = 16) {
	
  # Builds all necessary data from fst files in order to decide which events will be filtered by data filters
		
	assertthat::assert_that(all(grepl("\\.irf.fst$", irf_fst_files)),
		msg = "irf_fst_files must end in '.irf.fst'")
	assertthat::assert_that(all(file.exists(irf_fst_files)),
		msg = "Some IRFinder fst files do not exist")

	IRMode = match.arg(IRMode)
	assertthat::assert_that(IRMode != "",
		msg = "IRMode must be either 'SpliceOverMax' (default) or 'SpliceMax'")

  assertthat::assert_that(dir.exists(dirname(fst_path)),
    msg = paste(dirname(fst_path), "must exist"))

  if(!dir.exists(fst_path)) dir.create(fst_path)

	
  df = data.frame(sample = colData[,1], base_name = gsub("\\.irf.fst$", "", irf_fst_files),
    irf_file = irf_fst_files, stringsAsFactors = FALSE)
		
  df$splice_file = paste0(df$base_name, ".splice.fst")
	
	# skinny annotation
	irf.anno.brief = as.data.table(fst::read.fst(df$irf_file[1]))
	setnames(irf.anno.brief, "Name", "EventName")
	irf.anno.brief[, EventType := "IR"]
	irf.anno.brief[, EventRegion := paste0(seqnames, ":", start, "-", end, "/", strand)]
	irf.anno.brief = irf.anno.brief[, c("EventName", "EventType", "EventRegion")]
  splice.anno.brief = as.data.table(fst::read.fst(df$splice_file[1], c("EventName", "EventType", "EventRegion")))
	
	rowEvent = rbind(irf.anno.brief, splice.anno.brief)

  # Convert .txt.gz into .fst
  item.todo = c("Included", "Excluded", "Depth", "Coverage", "minDepth", "Up_Inc", "Down_Inc", "Up_Exc", "Down_Exc")
  
  for(item in item.todo) {
    filename = file.path(fst_path, paste(item, "txt.gz", sep="."))
    if(file.exists(filename)) file.remove(filename)
  }
  block = df
  
  n_jobs = ceiling(nrow(df) / samples_per_block)
  jobs = NxtIRF.SplitVector(seq_len(nrow(df)), n_jobs)
  
  for(j in seq_len(length(jobs))) {
    Included = copy(rowEvent)
    Excluded = copy(rowEvent)
    Depth = copy(rowEvent)
    Coverage = copy(rowEvent)
    minDepth = copy(rowEvent)
    
    Up_Inc = rowEvent[EventType %in% c("IR", "MXE", "SE")]
    Down_Inc = rowEvent[EventType %in% c("IR", "MXE", "SE")]
    Up_Exc = rowEvent[EventType %in% c("MXE")]		# for IR and SE, this defaults to rowEvent.Excluded
    Down_Exc = rowEvent[EventType %in% c("MXE")]

    block = df[jobs[[j]],]

    for(i in seq_len(nrow(block))) {
      irf = as.data.table(fst::read.fst(block$irf_file[i]))
      setnames(irf, "Name", "EventName")
      splice = as.data.table(fst::read.fst(block$splice_file[i]))
    
      # Included
      Included[, c(block$sample[i]) := c(
        irf$IntronDepth, 
        0.5 * (splice$count_Event1a[splice$EventType %in% c("SE", "MXE")] + 
          splice$count_Event2a[splice$EventType %in% c("SE", "MXE")]),
        splice$count_Event1a[!splice$EventType %in% c("SE", "MXE")]
      )]
      
      if(IRMode == "SpliceOverMax") {
        Excluded[, c(block$sample[i]) := c(
          irf$SpliceOverMax,
          0.5 * (splice$count_Event1b[splice$EventType %in% c("MXE")] + 
            splice$count_Event2b[splice$EventType %in% c("MXE")]),
          splice$count_Event1b[!splice$EventType %in% c("MXE")]
        )]
      } else {
        Excluded[, c(block$sample[i]) := c(
          irf$SpliceMaxMax,
          0.5 * (splice$count_Event1b[splice$EventType %in% c("MXE")] + 
            splice$count_Event2b[splice$EventType %in% c("MXE")]),
          splice$count_Event1b[!splice$EventType %in% c("MXE")]
        )]      
      }

      # Validity checking for IR, MXE, SE
      irf[strand == "+", Up_Inc := ExonToIntronReadsLeft]
      irf[strand == "-", Up_Inc := ExonToIntronReadsRight]
      irf[strand == "+", Down_Inc := ExonToIntronReadsRight]
      irf[strand == "-", Down_Inc := ExonToIntronReadsLeft]
      
      Up_Inc[, c(block$sample[i]) := c(irf$Up_Inc, splice$count_Event1a[splice$EventType %in% c("MXE", "SE")])]
      Down_Inc[, c(block$sample[i]) := c(irf$Down_Inc, splice$count_Event2a[splice$EventType %in% c("MXE", "SE")])]
      
      Up_Exc[, c(block$sample[i]) := splice$count_Event2a[splice$EventType %in% c("MXE")]]
      Down_Exc[, c(block$sample[i]) := splice$count_Event2b[splice$EventType %in% c("MXE")]]
      
      Depth[, c(block$sample[i]) := c(irf$TotalDepth, splice$TotalDepth)]
      Coverage[, c(block$sample[i]) := c(irf$Coverage, splice$coverage)]
      
      splice[EventType %in% c("MXE", "SE") & cov_up < cov_down, minDepth := count_JG_up]
      splice[EventType %in% c("MXE", "SE") & cov_up >= cov_down, minDepth := count_JG_down]
      splice[EventType %in% c("ALE", "A3SS"), minDepth := count_JG_up]
      splice[EventType %in% c("AFE", "A5SS"), minDepth := count_JG_down]
      
      minDepth[, c(block$sample[i]) := c(
        irf$IntronDepth,
        splice$minDepth)]
    }
    
    value = t(as.matrix(Included[, -c(1:3)]))
    fwrite(as.data.frame(value), file.path(fst_path, "Included.txt.gz"), 
      append = file.exists(file.path(fst_path, "Included.txt.gz")), 
      col.names = FALSE, row.names = FALSE)
    value = t(as.matrix(Excluded[, -c(1:3)]))
    fwrite(as.data.frame(value), file.path(fst_path, "Excluded.txt.gz"),  
      append = file.exists(file.path(fst_path, "Excluded.txt.gz")), 
      col.names = FALSE, row.names = FALSE)
    value = t(as.matrix(Depth[, -c(1:3)]))
    fwrite(as.data.frame(value), file.path(fst_path, "Depth.txt.gz"),  
      append = file.exists(file.path(fst_path, "Depth.txt.gz")), 
      col.names = FALSE, row.names = FALSE)
    value = t(as.matrix(Coverage[, -c(1:3)]))
    fwrite(as.data.frame(value), file.path(fst_path, "Coverage.txt.gz"),  
      append = file.exists(file.path(fst_path, "Coverage.txt.gz")), 
      col.names = FALSE, row.names = FALSE)
    value = t(as.matrix(minDepth[, -c(1:3)]))
    fwrite(as.data.frame(value), file.path(fst_path, "minDepth.txt.gz"),  
      append = file.exists(file.path(fst_path, "minDepth.txt.gz")), 
      col.names = FALSE, row.names = FALSE)
    value = t(as.matrix(Up_Inc[, -c(1:3)]))
    fwrite(as.data.frame(value), file.path(fst_path, "Up_Inc.txt.gz"),  
      append = file.exists(file.path(fst_path, "Up_Inc.txt.gz")), 
      col.names = FALSE, row.names = FALSE)
    value = t(as.matrix(Down_Inc[, -c(1:3)]))
    fwrite(as.data.frame(value), file.path(fst_path, "Down_Inc.txt.gz"),  
      append = file.exists(file.path(fst_path, "Down_Inc.txt.gz")), 
      col.names = FALSE, row.names = FALSE)
    value = t(as.matrix(Up_Exc[, -c(1:3)]))
    fwrite(as.data.frame(value), file.path(fst_path, "Up_Exc.txt.gz"),  
      append = file.exists(file.path(fst_path, "Up_Exc.txt.gz")), 
      col.names = FALSE, row.names = FALSE)
    value = t(as.matrix(Down_Exc[, -c(1:3)]))
    fwrite(as.data.frame(value), file.path(fst_path, "Down_Exc.txt.gz"),  
      append = file.exists(file.path(fst_path, "Down_Exc.txt.gz")), 
      col.names = FALSE, row.names = FALSE)
  }

  # Convert .txt.gz into .fst
  
  # Write rowData to fst
  fst::write.fst(rowEvent, file.path(fst_path, paste("rowEvent", "fst", sep=".")))
  
  for(item in item.todo) {
    infile = file.path(fst_path, paste(item, "txt.gz", sep="."))
    temp = t(fread(infile, data.table = FALSE))
    colnames(temp) = df$sample
    outfile = file.path(fst_path, paste(item, "fst", sep="."))
    fst::write.fst(as.data.frame(temp), outfile)
    file.remove(infile)
  }
  
}


runFilter <- function(filterClass, filterType, filterVars, filterObject) {
# Internal function
  # filterClass: can be one of 'Annotation', 'Data', 'Runtime'
  # filterType:
    # - Annotation:
    # - Data:
        # - Depth: 1-minimum, 2-minCond, 3-pcTRUE
        # - Coverage: 1-minimum, 1a-minDepth, 2-minCond, 3-pcTRUE
    # - Runtime:
        # - UpDown: compares upstream vs downstream derived PIR/PSI
	
	filterResult = rep(TRUE, nrow(filterObject))
				
  if(filterClass == "Data") {
    if(filterType == "Depth") {
      message("Running Depth filter")
      colData = SummarizedExperiment::colData(filterObject)
      use_cond = ifelse("condition" %in% names(filterVars), TRUE, FALSE)
      if(use_cond == TRUE) {
        cond_vec = unlist(colData[, which(colnames(colData) == filterVars$condition)])
        cond_vars = unique(cond_vec)
      }
      depth = as.matrix(SummarizedExperiment::assay(filterObject, "Depth"))
      
      sum_res = rep(0, nrow(filterObject))
      if(use_cond == TRUE) {
        for(cond in cond_vars) {
          depth.subset = depth[, which(cond_vec == cond)]
          sum = rowSums(depth.subset > filterVars$minimum)
          sum_res = sum_res + ifelse(sum * 100 / ncol(depth.subset) >= filterVars$pcTRUE, 1, 0)
        }
        n_TRUE = ifelse(!is.null(names(filterVars)) && "minCond" %in% names(filterVars), filterVars$minCond, -1)
        if(n_TRUE == -1) n_TRUE = length(cond_vars)
        res = (sum_res >= n_TRUE)
      } else {
        sum = rowSums(depth > filterVars$minimum)
        res = ifelse(sum * 100 / ncol(depth) >= filterVars$pcTRUE, TRUE, FALSE)
      }
      if("EventTypes" %in% names(filterVars)) {
        res[!(SummarizedExperiment::rowData(filterObject)$EventType %in% filterVars$EventTypes)] = TRUE
      }
      return(res)
    } else if(filterType == "Coverage") {
      message("Running Coverage filter")
      colData = SummarizedExperiment::colData(filterObject)
      use_cond = ifelse(!is.null(names(filterVars)) && "condition" %in% names(filterVars), TRUE, FALSE)
      if(use_cond == TRUE) {
        cond_vec = unlist(colData[, which(colnames(colData) == filterVars$condition)])
        cond_vars = unique(cond_vec)
      }
      cov = as.matrix(SummarizedExperiment::assay(filterObject, "Coverage"))
      depth = as.matrix(SummarizedExperiment::assay(filterObject, "minDepth"))
      cov[depth < filterVars$minDepth] = 1    # do not test if depth below threshold
      
      sum_res = rep(0, nrow(filterObject))
      if(use_cond == TRUE) {
        for(cond in cond_vars) {
          cov.subset = cov[, which(cond_vec == cond)]
          sum = rowSums(cov.subset > filterVars$minimum / 100)
          sum_res = sum_res + ifelse(sum * 100 / ncol(cov.subset) >= filterVars$pcTRUE, 1, 0)
        }
        n_TRUE = ifelse(!is.null(names(filterVars)) && "minCond" %in% names(filterVars), filterVars$minCond, -1)
        if(n_TRUE == -1) n_TRUE = length(cond_vars)
        res = (sum_res >= n_TRUE)
      } else {
        sum = rowSums(cov > filterVars$minimum / 100)
        res = ifelse(sum * 100 / ncol(cov) >= filterVars$pcTRUE, TRUE, FALSE)
      }
      if("EventTypes" %in% names(filterVars)) {
        res[!(SummarizedExperiment::rowData(filterObject)$EventType %in% filterVars$EventTypes)] = TRUE
      }
      return(res)
    }
  } else if(filterClass == "Annotation") {
		return(filterResult)
  } else {
    return(filterResult)
  }
}

